{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file outlines the method for creating an **embedding based** question answering system.\n",
    "Following are the major steps followed\n",
    "* Find the entity\n",
    "* Create a set of core chain candidates\n",
    "* Rank the core chain candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports (external library)\n",
    "import json\n",
    "import numpy as np\n",
    "import requests\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import create_data_node as cdn\n",
    "from utils import dbpedia_interface as dbi\n",
    "from utils import query_graph_to_sparql as qgts\n",
    "from utils import natural_language_utilities as nlutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entity linking\n",
    "\n",
    "We employ [EARL](http://sda.cs.uni-bonn.de/projects/earl/) which returns a set of candidate entities of which we use the top most one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['http://dbpedia.org/resource/India']\n"
     ]
    }
   ],
   "source": [
    "def get_entities(question,show_internals=False):\n",
    "    \"\"\"\n",
    "        uses EARL to find all the entites present in the question.\n",
    "        :param question: a natural language question.\n",
    "        :return: entities list.\n",
    "    \"\"\"\n",
    "\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "    }\n",
    "\n",
    "    data = '{\"nlquery\":\"%(p)s\"}'% {\"p\":question}\n",
    "    response = requests.post(' http://asknow02.sda.tech/earl/api/processQuery', headers=headers, data=data)\n",
    "    a = json.loads(response.content)\n",
    "    if show_internals:\n",
    "        pprint(a)\n",
    "    entity_list = []\n",
    "    for i in range(len(a['ertypes'])):\n",
    "        if a['ertypes'][i] == 'entity':\n",
    "            entity_list.append(a['rerankedlists'][str(i)][0][1]) # return the top most one. \n",
    "    return entity_list\n",
    "\n",
    "print(get_entities('Who is the president of India ?',False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sub Graph creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicate blacklist to exclude some of the meta data information\n",
    "pb = open('resources/predicate.blacklist').readlines()\n",
    "pb[-1] = pb[-1] + '\\n'\n",
    "pb = [r[:-1] for r in pb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Cache not found. Creating a new one\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/gaurav/codes/QA-Tutorial/utils/dbpedia_interface.py\", line 137, in __init__\n",
      "    self.labels = pickle.load(open('resources/labels.pickle'))\n",
      "TypeError: a bytes-like object is required, not 'str'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "few examples of hop1 candidates\n",
      "[['+', 'http://dbpedia.org/ontology/award'],\n",
      " ['-', 'http://dbpedia.org/property/creator'],\n",
      " ['-', 'http://dbpedia.org/ontology/executiveProducer'],\n",
      " ['-', 'http://dbpedia.org/property/screenplay'],\n",
      " ['+', 'http://dbpedia.org/property/education']]\n",
      "few examples of hop2 candidates\n",
      "[['-',\n",
      "  'http://dbpedia.org/ontology/writer',\n",
      "  '-',\n",
      "  'http://www.w3.org/2002/07/owl#differentFrom'],\n",
      " ['+',\n",
      "  'http://dbpedia.org/property/influences',\n",
      "  '-',\n",
      "  'http://dbpedia.org/property/others'],\n",
      " ['-',\n",
      "  'http://dbpedia.org/property/isCitedBy',\n",
      "  '+',\n",
      "  'http://dbpedia.org/property/journal'],\n",
      " ['+',\n",
      "  'http://dbpedia.org/ontology/influencedBy',\n",
      "  '-',\n",
      "  'http://dbpedia.org/property/characters'],\n",
      " ['+',\n",
      "  'http://dbpedia.org/ontology/deathPlace',\n",
      "  '-',\n",
      "  'http://dbpedia.org/ontology/significantProject']]\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    \n",
    "    cd_node = cdn.CreateDataNode(_predicate_blacklist=pb, _relation_file={}, _qald=False)\n",
    "    hop1,hop2  = cd_node.create_subgraph.subgraph\\\n",
    "                (['http://dbpedia.org/resource/Michael_Crichton'],[],_use_blacklist=True,_qald=False)\n",
    "\n",
    "    if True:\n",
    "        print('few examples of hop1 candidates')\n",
    "        pprint(hop1[:5])\n",
    "        print('few examples of hop2 candidates')\n",
    "        pprint(hop2[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(query):\n",
    "    '''\n",
    "        @TODO\n",
    "        \n",
    "        Add comments and replace the server logic with infile logic\n",
    "    '''\n",
    "    query_json = {'question':query}\n",
    "    v = requests.get(\"http://localhost:3500/vec\", json=query_json)\n",
    "    v = np.asarray(v.json())\n",
    "    v = np.mean(v.astype(np.float), axis=0)\n",
    "    return v\n",
    "\n",
    "\n",
    "def assign_score(core_chain,question):\n",
    "    '''\n",
    "        potential code stub.\n",
    "    '''\n",
    "    if len(core_chain) == 2:\n",
    "        # corechain looks like ['+', 'http:.../abc']\n",
    "        predicate = nlutils.get_label_via_parsing(core_chain[1],lower=True)\n",
    "    else:\n",
    "        # corechain looks like ['+' 'http:../abc', '-', 'http:../pqr']\n",
    "        predicate = [nlutils.get_label_via_parsing(core_chain[1],lower=True),\n",
    "                     nlutils.get_label_via_parsing(core_chain[3],lower=True)]\n",
    "        predicate = \" \".join(predicate)\n",
    "    \n",
    "    question_vector = get_vector(query=question)\n",
    "    predicate_vector = get_vector(query=predicate)\n",
    "    \n",
    "    if np.sum(question_vector) == 0.0 or np.sum(predicate_vector) == 0:\n",
    "        return np.float64(0.0)\n",
    "    else:\n",
    "        return np.dot(predicate_vector, question_vector) / (np.linalg.norm(predicate_vector) *\n",
    "                                                            np.linalg.norm(question_vector))\n",
    "    \n",
    "    # predicate is a string seperated by space -- 'abc pqr'\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading dataset. \n",
    "\n",
    "The dataset consists of 2000 questions without any rdf constraint or count or ask. It is just composed of single hop or two hop query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = json.load(open('resources/dataset_with_paths.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation\n",
    "\n",
    "The code snippets for evaluating sparql with respect to ground truth sparql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparql_answer(sparql,dbi=None):\n",
    "    '''\n",
    "        Executes the sparql on dbpedia and returns answer as a list.\n",
    "        :param sparql: SPARQL which will be executed.\n",
    "        :param dbi: The dbpedia interface object which can be used for accesing dbpedia.\n",
    "    '''\n",
    "    if not dbi:\n",
    "        dbi = dbp\n",
    "    test_answer = []\n",
    "    interface_test_answer = dbi.get_answer(sparql)\n",
    "    for key in interface_test_answer:\n",
    "        test_answer = test_answer + interface_test_answer[key]\n",
    "    return list(set(test_answer))\n",
    "\n",
    "\n",
    "def _evaluate_sparqls_(test_sparql, true_sparql,dbp):\n",
    "    # @TODO: If the type of test and true are differnt code would return an error.\n",
    "    \"\"\"\n",
    "        Fmeasure for ask and count are 0/1.\n",
    "        Also assumes the variable to be always uri.\n",
    "        :param test_sparql: SPARQL generated by the pipeline\n",
    "        :param true_sparql: True SPARQL\n",
    "        :param type: COUNT/ASK/LIST\n",
    "        :return: f1,precision,recall\n",
    "    \"\"\"\n",
    "    test_answer = sparql_answer(test_sparql,dbp)\n",
    "    true_answer = sparql_answer(true_sparql,dbp)\n",
    "    total_retrived_resutls = len(test_answer)\n",
    "    total_relevant_resutls = len(true_answer)\n",
    "    common_results = total_retrived_resutls - len(list(set(test_answer ) -set(true_answer)))\n",
    "    if total_retrived_resutls == 0:\n",
    "        precision = 0\n",
    "    else:\n",
    "        precision = common_results *1.0 /total_retrived_resutls\n",
    "    if total_relevant_resutls == 0:\n",
    "        recall = 0\n",
    "    else:\n",
    "        recall = common_results *1.0 /total_relevant_resutls\n",
    "    if precision == 0 and recall == 0:\n",
    "        f1 = 0\n",
    "    else:\n",
    "        f1 = (2.0 * (precision * recall)) / (precision + recall)\n",
    "    return f1 ,precision ,recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Putting it all together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4739299003444137"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ranking\n",
    "core_chain = dataset[0]['hop1'][1]\n",
    "question = 'Who is the president of India ?'\n",
    "assign_score(core_chain,question)\n",
    "\n",
    "\n",
    "# Core chain to SPARQL\n",
    "graph = {\n",
    "    'best_path' : ['+', 'http://dbpedia.org/property/party', '+', 'http://dbpedia.org/ontology/ideology'],\n",
    "    'entities' : ['http://dbpedia.org/resource/Michael_Crichton']\n",
    "}\n",
    "qgts.convert_runtime(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Cache not found. Creating a new one\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/gaurav/codes/QA-Tutorial/utils/dbpedia_interface.py\", line 137, in __init__\n",
      "    self.labels = pickle.load(open('resources/labels.pickle'))\n",
      "TypeError: a bytes-like object is required, not 'str'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a252139f392d4f31b430633280789711",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d042d66023b541c99440541d24d959ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a64a15eb86b04cfd85e35892fca195a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcf4e01de7a94475ad83a85ea9a58c34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.0 1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc73bdbda447473ab6fb2e405534ac92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.0 1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f796e887156b4757bc9062f95e739db8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a32192d3ccc544f1ba7ed3f195fa590b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "988322312db94fa88f0e608075919e6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c95c78b84e94a74a3e1da0bcf813855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5ac56ad322e4b0c8772eb84917593a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d34f4eda7b34e81b6c870bdfe6576e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.0 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# potential code stub\n",
    "dbp = dbi.DBPedia()\n",
    "precision = []\n",
    "for node in tqdm(dataset[:10]):\n",
    "\n",
    "    max_score = 0.0\n",
    "    max_index = -1\n",
    "    \n",
    "    for index,cc in tqdm(enumerate([node['path']]+node['hop1']+node['hop2'])):\n",
    "\n",
    "        # Find the score of the core chain\n",
    "        score = assign_score(cc,node['node']['corrected_question'])\n",
    "\n",
    "        # check if score is higher when compared to max_score and if so,\n",
    "        # updated the max_score and index.\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            max_index = index\n",
    "    \n",
    "    # if max_index is zero, it means the highest score was for the correct path.\n",
    "    if max_index == 0:\n",
    "        precision.append(1)\n",
    "    else:\n",
    "        precision.append(0)\n",
    "    \n",
    "    # find the highest scored path (corechain - cc.)\n",
    "    combined = [node['path']]+node['hop1']+node['hop2']\n",
    "    best_cc =  combined[max_index]\n",
    "    \n",
    "    # convert the highest scored cc to SPARQL.\n",
    "    graph = {\n",
    "        'best_path' : best_cc,\n",
    "        'entities' : node['entity']\n",
    "    }\n",
    "    \n",
    "\n",
    "    sparql = qgts.convert_runtime(graph)\n",
    "    f,p,r = _evaluate_sparqls_(test_sparql=sparql, true_sparql=node['node']['sparql_query'],dbp=dbp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
